{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33826d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score, ConfusionMatrix\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "from torchvision import transforms\n",
    "from torchvision.io import decode_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea376e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set seeds and device\"\"\"\n",
    "np.random.seed(73)\n",
    "torch.manual_seed(73)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(73)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dece2ca",
   "metadata": {},
   "source": [
    "Prepare data for CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06df499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Custom classes for loading data through dataloader as adapted from https://docs.pytorch.org/tutorials/beginner/data_loading_tutorial.html\"\"\"\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = Path(self.img_dir, self.img_labels.iloc[idx, 1])\n",
    "        image = decode_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 2]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d41d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load data using custom class defined above and split into train/validate/test datasets\"\"\"\n",
    "DATA_PATH = Path(Path.cwd().parent, \"Data\")\n",
    "data_transformers=transforms.Compose([transforms.ToPILImage(),\n",
    "                                      transforms.ToTensor()])\n",
    "\n",
    "leaf_dataset = SpectrogramDataset(annotations_file=Path(DATA_PATH, \"Spectrogram\", \"all.csv\"), img_dir=Path(DATA_PATH, \"Spectrogram\"), transform=data_transformers)\n",
    "train_dataset, valid_dataset, test_dataset = random_split(leaf_dataset, [0.6, 0.2, 0.2])\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3663981",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Convert those datasets into batch loaders\"\"\"\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5090277f",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fa8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Combined CNN-LSTM architecture as adapted from https://www.mathworks.com/help/deeplearning/ug/sequence-classification-using-cnn-lstm-network.html\"\"\"\n",
    "class ComposerCNN(nn.Module):\n",
    "    def __init__(self, input_size, filter_size, num_filters, num_hidden_units, num_classes):\n",
    "        super(ComposerCNN, self).__init__()\n",
    "        self.convolve = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_size, out_channels=num_filters, kernel_size=filter_size, padding=\"same\"),\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=num_filters, out_channels=num_filters, kernel_size=filter_size, padding=\"same\"),\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(4, 2), stride=(4, 2)),\n",
    "\n",
    "            nn.Conv2d(in_channels=num_filters, out_channels=2*num_filters, kernel_size=filter_size, padding=\"same\"),\n",
    "            nn.BatchNorm2d(2*num_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(4, 2), stride=(4, 2)),\n",
    "\n",
    "            nn.Conv2d(in_channels=2*num_filters, out_channels=2*num_filters, kernel_size=filter_size, padding=\"same\"),\n",
    "            nn.BatchNorm2d(2*num_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(4, 2), stride=(4, 2)),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            #TODO : Add fully connected layers here\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convolve(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ca8c5f",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad01c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Define training loop for CNN-LSTM model\"\"\"\n",
    "def train(model, training, validation, lr=0.001):\n",
    "\tcriterion = nn.CrossEntropyLoss()\n",
    "\toptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\t\n",
    "\ttrain_losses = []\n",
    "\tfor inputs, labels in training:\n",
    "\t\tmodel.train()\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutput = model(inputs)\n",
    "\t\tloss = criterion(output, labels)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\ttrain_losses.append(loss.item())\n",
    "\t\tbreak\n",
    "\n",
    "\tvalidation_losses = []\n",
    "\twith torch.no_grad():\n",
    "\t\tfor v_inputs, v_labels in validation:\n",
    "\t\t\tmodel.eval()\n",
    "\t\t\tv_output = model(v_inputs)\n",
    "\t\t\tvalidation_loss = criterion(v_output, v_labels)\t\n",
    "\t\t\tvalidation_losses.append(validation_loss.item())\n",
    "\t\t\tbreak\n",
    "\treturn train_losses, validation_losses\n",
    "\n",
    "# Train CNN model\n",
    "epochs = 300\n",
    "model = ComposerCNN(input_size=1, filter_size=3, num_filters=64, num_hidden_units=256, num_classes=4)\n",
    "\n",
    "total_train_losses = []\n",
    "total_validation_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\tepoch_train_loss, epoch_validation_loss = train(model, train_loader, valid_loader)\n",
    "\ttotal_train_losses.extend(epoch_train_loss)\n",
    "\ttotal_validation_losses.extend(epoch_validation_loss)\n",
    "\tif (epoch + 1) % 10 == 0:\n",
    "\t\tprint(f\"Epoch {epoch + 1}, train loss: {epoch_train_loss[-1]:.4f}, validation loss: {epoch_validation_loss[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8548806",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot training and Validation losses\"\"\"\n",
    "plt.title(\"LSTM training losses\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "\n",
    "plt.plot(total_train_losses, label=\"Train loss\")\n",
    "plt.plot(total_validation_losses, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f4c0e3",
   "metadata": {},
   "source": [
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fde0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create tensors to use in performance metric creation\"\"\"\n",
    "prediction = torch.Tensor()\n",
    "truth = torch.Tensor()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        prediction = torch.cat([prediction, predicted], dim=0)\n",
    "        truth = torch.cat([truth, labels], dim=0)\n",
    "        \n",
    "assert prediction.shape == truth.shape\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0535b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create performance metrics\"\"\"\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=32)\n",
    "precision = Precision(task=\"multiclass\", average=\"macro\", num_classes=32)\n",
    "recall = Recall(task=\"multiclass\", average=\"macro\", num_classes=32)\n",
    "f1_score = F1Score(task=\"multiclass\", average=\"macro\", num_classes=32)\n",
    "confusion_matric = ConfusionMatrix(task=\"multiclass\", num_classes=32)\n",
    "\n",
    "calculated_accuracy = accuracy(truth, prediction)\n",
    "calculated_precision = precision(truth, prediction)\n",
    "calculated_recall = recall(truth, prediction)\n",
    "calculated_f1_score = f1_score(truth, prediction)\n",
    "calculated_confusion_matric = confusion_matric(truth, prediction)\n",
    "\n",
    "print(\"Model Accuracy:\", calculated_accuracy)\n",
    "print(\"Model Precision:\", calculated_precision)\n",
    "print(\"Model Recall:\", calculated_recall)\n",
    "print(\"Model F1:\", calculated_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a4346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Vizulaize confusion matrix\"\"\"\n",
    "metric = MulticlassConfusionMatrix(num_classes=4)\n",
    "metric.update(truth, prediction)\n",
    "fig_, ax_ = metric.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9907c54",
   "metadata": {},
   "source": [
    "Optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff0814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: play with the parameters and optimize the CNN architecture"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
